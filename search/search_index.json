{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"[dir=\"ltr\"] .md-sidebar--primary:not([hidden]) ~ .md-content > .md-content__inner { margin-left: 0;} div.md-source-file {color: black; margin-left: 1rem;} Daffy Minimize Cloud Pak & OpenShift Build Time .button { border: none; color: white; padding: 15px 32px; text-align: center; text-decoration: none; display: inline-block; font-size: 16px; margin: 4px 2px; cursor: pointer; }</p> <p>.button1 {background-color: #4CAF50;} /<em> Green </em>/ .button2 {background-color: #008CBA;} /<em> Blue </em>/ First Time User Experienced User Daffy is D eployment A utomation F ramework F or Y ou. A tool to do all the heavy lifting of the OpenShift and IBM Cloud Pak installs. The National Market Top Team created Daffy to assist the technical sales teams with the progression of IBM Cloud Pak opportunities. The goal is to provide the technical sales with a set of (easy to use) scripts that will aid in the installation of OpenShift and the IBM Cloud Pak's. Using Daffy IBMers, business partners and customers are onboarded to IBM Cloud Pak's in less than a few hours, removing challenges that previously existing setting up OpenShift. Important Daffy scripts were designed to help pre-sales(CTP/BP) with POC deployments. If you choose to use this in a production environment, you may, but it will be on the installer for support of that installation. IBM can not give support for that deployment with the Daffy tool. The installer/business partner would need to verify the environment that it meets all HA , best practices, management aspects and security requirements. As this is a scripting engine, you have full access to the logic/code and have ability to make any changes you feel fit. If you do make any changes to the daffy engine outside of your cluster environment file, you are on your own, we will not be able to assistant with that environment. Please Refer to the Production Deployment Guides for the recommended approach when advising customers on how to deploy a Production Ready Environment. \u00b6 All roads lead to Cloud Pak. The Daffy automation process is a three step process . You can start at step 1 or step 2 or even step 3 . For example, If you do not have a cluster, start at step 1. If you have OpenShift Cluster already, start at step 2. If you have a OpenShift cluster and already have base cloud pak installed, but just need to deploy a cloud pak service, start at step 3. HTML Video embed","title":"Home"},{"location":"#daffy-scripts-were-designed-to-help-pre-salesctpbp-with-poc-deployments-if-you-choose-to-use-this-in-a-production-environment-you-may-but-it-will-be-on-the-installer-for-support-of-that-installation-ibm-can-not-give-support-for-that-deployment-with-the-daffy-tool-the-installerbusiness-partner-would-need-to-verify-the-environment-that-it-meets-all-ha-best-practices-management-aspects-and-security-requirements-as-this-is-a-scripting-engine-you-have-full-access-to-the-logiccode-and-have-ability-to-make-any-changes-you-feel-fit-if-you-do-make-any-changes-to-the-daffy-engine-outside-of-your-cluster-environment-file-you-are-on-your-own-we-will-not-be-able-to-assistant-with-that-environment-please-refer-to-the-production-deployment-guides-for-the-recommended-approach-when-advising-customers-on-how-to-deploy-a-production-ready-environment","text":"All roads lead to Cloud Pak. The Daffy automation process is a three step process . You can start at step 1 or step 2 or even step 3 . For example, If you do not have a cluster, start at step 1. If you have OpenShift Cluster already, start at step 2. If you have a OpenShift cluster and already have base cloud pak installed, but just need to deploy a cloud pak service, start at step 3. HTML Video embed","title":"Daffy scripts were designed to help pre-sales(CTP/BP) with POC deployments. If you choose to use this in a production environment, you may, but it will be on the installer for support of that installation.  IBM can not give support for that deployment with the Daffy tool. The installer/business partner would need to verify  the environment that it meets all HA , best practices, management aspects and security requirements. As this is a scripting engine, you have full access to the logic/code and have ability to make any changes you feel fit. If you do make any changes to the daffy engine outside of your cluster environment file, you are on your own, we will not be able to assistant with that environment.  Please Refer to the Production Deployment Guides for the recommended approach when advising customers on how to deploy a Production Ready Environment."},{"location":"Cloud-Paks/Business-Automation/","text":"","title":"Business Automation"},{"location":"Cloud-Paks/Data/","text":"Cloud Pak for Data \u00b6 Step 1: Deploy Cloud Pak \u00b6 Deploying the Cloud Pak for Data requires one entries to your environment file (/data/daffy/env/ -env.sh). CP4D_VERSION= With these values, the daffy engine will be able to install the version of Cloud Pak for Data and prepare for the desired services. CP4D Supported Version OCP Versions 4.0.5 4.6, 4.8 4.0.4 4.6, 4.8 4.0.3 4.6, 4.8 4.0.2 4.6 You can copy the following to your -env.sh CP4D_VERSION=\"4.0.5\" Run the following command to deploy the Cloud Pak for Data /data/daffy/cp4d/build.sh <ENVIRONMENT_NAME> When this step is complete, approx 60 minutes depending on your environment, you have the Cloud Pak running. This is just the core Cloud Pak operators, no service/pattern is running at this point. The cluster is now ready to deploy the services/patterns. At this stage, the cluster consist of bedrock operators and the Cloud Pak for Data operators in the following projects: cpd-instance cpd-operators ibm-common-services Step 2: Deploying Service \u00b6 Deploying the Cloud Pak for Data requires some entries to your environment file ( -env.sh). The current services supported are Watson Knowledge Studio (WKS), Watson Knowledge Catalog (WKC), Data Virtualization (DV), Watson Studio (WS), Statistical Package for Social Sciences (SPSS), and Watson Machine Learning (WML) CP4D_ENABLE_SERVICE_WKS=<true|false> CP4D_ENABLE_SERVICE_WKC=<true|false> CP4D_ENABLE_SERVICE_DV=<true|false> CP4D_ENABLE_SERVICE_WS=<true|false> CP4D_ENABLE_SERVICE_SPSS=<true|false> CP4D_ENABLE_SERVICE_WML=<true|false> CP4D_ENABLE_SERVICE_DATASTAGE=<true|false> CP4D_ENABLE_SERVICE_DODS=<true|false> CP4D_ENABLE_SERVICE_DMC=<true|false> CP4D_ENABLE_SERVICE_COGNOS=<true|false> With these values, the daffy engine will be able to install the version of Cloud Pak for Data and prepare for the desired services. WKS - Watson Knowledge Studio WKC - Watson Knowledge Catalog DV - Data Virtualization WS - Watson Studio SPSS - Statistical Package for Social Sciences WML - Watson Machine Learning DataStage - DataStage DODS - Decision Optimization DMC - DB2 Management Console Cognos - Cognos Run the following command to deploy the Cloud Pak for Data services. /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> Step 3: Status of Deployment \u00b6 The service can take a few hours to complete, based on which one you chose to deploy. To help monitor the status of the service deployment you can run the --help flag to see what flags you can use to get information on your service deployment. Run the following commands to check the Cloud Pak for Data to see what command flags you can run /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --help The following command will give you the status of all components for the pattern you deployed /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --AllStatus If you want to have a running job to refresh every few seconds, you can run the above command via the watch command. watch -c /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --AllStatus If you want to want to see more detail status on an individual service, you can run each service status. /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --WKCStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --WKSStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --WSStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --DVStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --WMLStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --SPSSStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --DataStageStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --DODSStatus /data/daffy/cp4d/build.sh <ENVIRONMENT_NAME> --Console","title":"Data"},{"location":"Cloud-Paks/Data/#cloud-pak-for-data","text":"","title":"Cloud Pak for Data"},{"location":"Cloud-Paks/Data/#step-1-deploy-cloud-pak","text":"Deploying the Cloud Pak for Data requires one entries to your environment file (/data/daffy/env/ -env.sh). CP4D_VERSION= With these values, the daffy engine will be able to install the version of Cloud Pak for Data and prepare for the desired services. CP4D Supported Version OCP Versions 4.0.5 4.6, 4.8 4.0.4 4.6, 4.8 4.0.3 4.6, 4.8 4.0.2 4.6 You can copy the following to your -env.sh CP4D_VERSION=\"4.0.5\" Run the following command to deploy the Cloud Pak for Data /data/daffy/cp4d/build.sh <ENVIRONMENT_NAME> When this step is complete, approx 60 minutes depending on your environment, you have the Cloud Pak running. This is just the core Cloud Pak operators, no service/pattern is running at this point. The cluster is now ready to deploy the services/patterns. At this stage, the cluster consist of bedrock operators and the Cloud Pak for Data operators in the following projects: cpd-instance cpd-operators ibm-common-services","title":"Step 1: Deploy Cloud Pak"},{"location":"Cloud-Paks/Data/#step-2-deploying-service","text":"Deploying the Cloud Pak for Data requires some entries to your environment file ( -env.sh). The current services supported are Watson Knowledge Studio (WKS), Watson Knowledge Catalog (WKC), Data Virtualization (DV), Watson Studio (WS), Statistical Package for Social Sciences (SPSS), and Watson Machine Learning (WML) CP4D_ENABLE_SERVICE_WKS=<true|false> CP4D_ENABLE_SERVICE_WKC=<true|false> CP4D_ENABLE_SERVICE_DV=<true|false> CP4D_ENABLE_SERVICE_WS=<true|false> CP4D_ENABLE_SERVICE_SPSS=<true|false> CP4D_ENABLE_SERVICE_WML=<true|false> CP4D_ENABLE_SERVICE_DATASTAGE=<true|false> CP4D_ENABLE_SERVICE_DODS=<true|false> CP4D_ENABLE_SERVICE_DMC=<true|false> CP4D_ENABLE_SERVICE_COGNOS=<true|false> With these values, the daffy engine will be able to install the version of Cloud Pak for Data and prepare for the desired services. WKS - Watson Knowledge Studio WKC - Watson Knowledge Catalog DV - Data Virtualization WS - Watson Studio SPSS - Statistical Package for Social Sciences WML - Watson Machine Learning DataStage - DataStage DODS - Decision Optimization DMC - DB2 Management Console Cognos - Cognos Run the following command to deploy the Cloud Pak for Data services. /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME>","title":"Step 2: Deploying Service"},{"location":"Cloud-Paks/Data/#step-3-status-of-deployment","text":"The service can take a few hours to complete, based on which one you chose to deploy. To help monitor the status of the service deployment you can run the --help flag to see what flags you can use to get information on your service deployment. Run the following commands to check the Cloud Pak for Data to see what command flags you can run /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --help The following command will give you the status of all components for the pattern you deployed /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --AllStatus If you want to have a running job to refresh every few seconds, you can run the above command via the watch command. watch -c /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --AllStatus If you want to want to see more detail status on an individual service, you can run each service status. /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --WKCStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --WKSStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --WSStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --DVStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --WMLStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --SPSSStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --DataStageStatus /data/daffy/cp4d/service.sh <ENVIRONMENT_NAME> --DODSStatus /data/daffy/cp4d/build.sh <ENVIRONMENT_NAME> --Console","title":"Step 3: Status of Deployment"},{"location":"Cloud-Paks/Integration/","text":"","title":"Integration"},{"location":"Cloud-Paks/Watson-AIOPS/","text":"","title":"Watson AIOPS"},{"location":"Cloud-Paks/WebSphere-Automation/","text":"","title":"WebSphere Automation"},{"location":"Deploying-OCP/AWS/","text":"Step 1 Platform Requirements \u00b6 testing admonition feature, no danger To use Daffy on Amazon Web Services , there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For AWS , it breaks down to the following basic three items: Account Details - The account that you plan to install OpenShift Permissions - The permissions need to perform the install Quota - The ability to add new workload to that platform For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. https://ibm.box.com/v/DaffyProviderRequirements Step 2 Finding Provider Details \u00b6 To install Daffy on AWS , the hardest part can be finding the provider details in the portal. To create or use an existing AWS Access Key ID you can refer to this: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html?icmpid=docs_iam_console#Using_CreateAccessKey Note: Use the Identity and Access Management (IAM) service to manage access keys. Select Search - find IAM service You can create a new access key or use an existing key. The access key must have authority to the account you wan to install OpenShift into. Secret Access Key: The secret access key is ONLY displayed at the time of creation. When you create the access key, you will then have the opportunity to capture the secret access key Note: This is sensitive information, please make sure you store this in a secure location The screen to the right is an example of what you will see when you create a NEW access Key. Region: For you to use Daffy to install on AWS you need to choose a valid region identifier. This will be the target region you are planning to deploy OpenShift into. To see a complete list of available AWS Regions, you can select the region drop down list in the AWA Portal. This will be in the upper right hand corner next to your account name. (See picture to the right) Note: Take note of the region identifier such as: us-east-2. This is the value you would use to deploy a OCP cluster into the US East (Ohio) region. Permission: Within your AWS project, you would need to go to IAM Section and make sure the user that is associated with your Access Key is assigned the correct roles. At minimum, you need to have this role: AdministratorAccess Please see the requirements doc for more information! Hosted Zone: For each OpenShift deployment into AWS , you need to create a Route 53 Hosted Zone . Important : You must create a Hosted Zone that exactly matches your Base Domain. Important: Once you create your Hosted Zone, you must point your DNS registry Name Server records to the assigned AWS DNS Name Server records listed in this Hosted Zone. You will see the Name Servers listed once you have created the Hosted Zone. {: .notice} Hello Dan Hello Tan","title":"AWS"},{"location":"Deploying-OCP/AWS/#step-1-platform-requirements","text":"testing admonition feature, no danger To use Daffy on Amazon Web Services , there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For AWS , it breaks down to the following basic three items: Account Details - The account that you plan to install OpenShift Permissions - The permissions need to perform the install Quota - The ability to add new workload to that platform For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. https://ibm.box.com/v/DaffyProviderRequirements","title":"Step 1 Platform Requirements"},{"location":"Deploying-OCP/AWS/#step-2-finding-provider-details","text":"To install Daffy on AWS , the hardest part can be finding the provider details in the portal. To create or use an existing AWS Access Key ID you can refer to this: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html?icmpid=docs_iam_console#Using_CreateAccessKey Note: Use the Identity and Access Management (IAM) service to manage access keys. Select Search - find IAM service You can create a new access key or use an existing key. The access key must have authority to the account you wan to install OpenShift into. Secret Access Key: The secret access key is ONLY displayed at the time of creation. When you create the access key, you will then have the opportunity to capture the secret access key Note: This is sensitive information, please make sure you store this in a secure location The screen to the right is an example of what you will see when you create a NEW access Key. Region: For you to use Daffy to install on AWS you need to choose a valid region identifier. This will be the target region you are planning to deploy OpenShift into. To see a complete list of available AWS Regions, you can select the region drop down list in the AWA Portal. This will be in the upper right hand corner next to your account name. (See picture to the right) Note: Take note of the region identifier such as: us-east-2. This is the value you would use to deploy a OCP cluster into the US East (Ohio) region. Permission: Within your AWS project, you would need to go to IAM Section and make sure the user that is associated with your Access Key is assigned the correct roles. At minimum, you need to have this role: AdministratorAccess Please see the requirements doc for more information! Hosted Zone: For each OpenShift deployment into AWS , you need to create a Route 53 Hosted Zone . Important : You must create a Hosted Zone that exactly matches your Base Domain. Important: Once you create your Hosted Zone, you must point your DNS registry Name Server records to the assigned AWS DNS Name Server records listed in this Hosted Zone. You will see the Name Servers listed once you have created the Hosted Zone. {: .notice} Hello Dan Hello Tan","title":"Step 2 Finding Provider Details"},{"location":"Deploying-OCP/Azure/","text":"PREREQ CORE STEPS At this point, you have a bastion machine where you have installed the Daffy tool, created your core environment-name -env.sh and can execute the install of OCP on ROKS. Step 1 Platform Requirements \u00b6 To use Daffy on Azure , there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For Azure , it breaks down to the following basic three items: Account Details - The account that you plan to install OpenShift Permissions - The permissions need to perform the install Quota - The ability to add new workload to that platform For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. https://ibm.box.com/v/DaffyProviderRequirements Step 2 Finding Provider Details \u00b6 To install Daffy on Azure, the hardest part can be finding the provider details. Subscription ID:Details coming soon !!! Client ID:Details coming soon !!! Client Secret:Details coming soon !!! Tenant ID:Details coming soon !!! Base Domain Resource Group Name:Details coming soon !!! Region:Details coming soon !!! Quota:Details coming soon !!! Permission: Within your Azure project, you would need to go to IAM Section and create/use Service Account. From the requirements doc, make sure your service account has the correct permissions. Dedicated public host Zone: You will need to create a DNS Zone within a new/existing resource group. For the OpenShift install, you need the following: Registered DNS Name - myexample.com Azure DNS Zone - myexample-com Transfer the domain to Azure Name services listed in your new Azure DNS Zone Setting up DNS for Azure Deployment with OpenShift: insert video Here Step 3 Environment File \u00b6 Deploying the OpenShift on Azure only requires three entries to your existing core environment file ( -env.sh) plus a local service account file. Note: You can look in the samples directory on your bastion for example of Azure install : /data/daffy/env/samples/ azure-ipi-env.sh You can copy the sample file to build your new environment file. OCP_INSTALL_TYPE=\"azure-ipi\" AZURE_SUBSCRIPTION_ID=\"999999-999999-999999-99999\" AZURE_CLIENT_ID=\"999999-999999-999999-99999\" AZURE_TENANT_ID=\"999999-999999-999999-99999\" AZURE_BASE_DOMAIN_RESOURCE_GROUP_NAME=\"<YOUR_RESOURCE_GROUP_FOR_DNS>\" AZURE_REGION=\"<YOUR_REGION>\" #OCP_CREATE_OPENSHIFT_CONTAINER_STORAGE=true Valid Options: OCP_INSTALL_TYPE =\"azure-ipi\" AZURE_SUBSCRIPTION_ID =\" \" AZURE_CLIENT_ID =\" \" AZURE_TENANT_ID = \" AZURE_BASE_DOMAIN_RESOURCE_GROUP_NAME = \" AZURE_REGION =\" \" Optional: OCP_CREATE_OPENSHIFT_CONTAINER_STORAGE =true If you plan to install a cloud pak and/or need storage, you need to set the flag to setup OCS Storage ** It will prompt you for the Client Secret during the install. Step 4 Execution \u00b6 To deploy your OCP cluster to Azure , run the build.sh script from the /data/daffy/ocp directory /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> Once your cluster is fully deployed you can access the help menu which has a number of options. Note: is the first part of your name that you used for the < ENVIRONMENT_NAME >-env.sh file Here is a full example for deploying OpenShfit on Azure with the Daffy process.","title":"Azure"},{"location":"Deploying-OCP/Azure/#step-1-platform-requirements","text":"To use Daffy on Azure , there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For Azure , it breaks down to the following basic three items: Account Details - The account that you plan to install OpenShift Permissions - The permissions need to perform the install Quota - The ability to add new workload to that platform For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. https://ibm.box.com/v/DaffyProviderRequirements","title":"Step 1 Platform Requirements"},{"location":"Deploying-OCP/Azure/#step-2-finding-provider-details","text":"To install Daffy on Azure, the hardest part can be finding the provider details. Subscription ID:Details coming soon !!! Client ID:Details coming soon !!! Client Secret:Details coming soon !!! Tenant ID:Details coming soon !!! Base Domain Resource Group Name:Details coming soon !!! Region:Details coming soon !!! Quota:Details coming soon !!! Permission: Within your Azure project, you would need to go to IAM Section and create/use Service Account. From the requirements doc, make sure your service account has the correct permissions. Dedicated public host Zone: You will need to create a DNS Zone within a new/existing resource group. For the OpenShift install, you need the following: Registered DNS Name - myexample.com Azure DNS Zone - myexample-com Transfer the domain to Azure Name services listed in your new Azure DNS Zone Setting up DNS for Azure Deployment with OpenShift: insert video Here","title":"Step 2 Finding Provider Details"},{"location":"Deploying-OCP/Azure/#step-3-environment-file","text":"Deploying the OpenShift on Azure only requires three entries to your existing core environment file ( -env.sh) plus a local service account file. Note: You can look in the samples directory on your bastion for example of Azure install : /data/daffy/env/samples/ azure-ipi-env.sh You can copy the sample file to build your new environment file. OCP_INSTALL_TYPE=\"azure-ipi\" AZURE_SUBSCRIPTION_ID=\"999999-999999-999999-99999\" AZURE_CLIENT_ID=\"999999-999999-999999-99999\" AZURE_TENANT_ID=\"999999-999999-999999-99999\" AZURE_BASE_DOMAIN_RESOURCE_GROUP_NAME=\"<YOUR_RESOURCE_GROUP_FOR_DNS>\" AZURE_REGION=\"<YOUR_REGION>\" #OCP_CREATE_OPENSHIFT_CONTAINER_STORAGE=true Valid Options: OCP_INSTALL_TYPE =\"azure-ipi\" AZURE_SUBSCRIPTION_ID =\" \" AZURE_CLIENT_ID =\" \" AZURE_TENANT_ID = \" AZURE_BASE_DOMAIN_RESOURCE_GROUP_NAME = \" AZURE_REGION =\" \" Optional: OCP_CREATE_OPENSHIFT_CONTAINER_STORAGE =true If you plan to install a cloud pak and/or need storage, you need to set the flag to setup OCS Storage ** It will prompt you for the Client Secret during the install.","title":"Step 3 Environment File"},{"location":"Deploying-OCP/Azure/#step-4-execution","text":"To deploy your OCP cluster to Azure , run the build.sh script from the /data/daffy/ocp directory /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> Once your cluster is fully deployed you can access the help menu which has a number of options. Note: is the first part of your name that you used for the < ENVIRONMENT_NAME >-env.sh file Here is a full example for deploying OpenShfit on Azure with the Daffy process.","title":"Step 4 Execution"},{"location":"Deploying-OCP/Core-steps/","text":"Step 1: Access your bastion Server \u00b6 Create Bastion Steps *** If you do not have a bastion, above button/link will walk you thru the process to create a Linux bastion server. Step 2: Install Daffy \u00b6 Log into your Bastion Machine (as root) and run the following command to download the latest Daffy Scripts. wget http://get.daffy-installer.com/download-scripts/daffy-init.sh; chmod 777 daffy-init.sh;./daffy-init.sh Step 3: Create -env.sh \u00b6 DAFFY_UNIQUE_ID=\"<YourID@ibm.com>\" #This is required - Values POC/Demo/Enablement/HCCX/TechZone DAFFY_DEPLOYMENT_TYPE=\"\" #If POC/Demo, these are required. #ISC number must be 18 characters #DAFFY_ISC_NUMBER=\"0045h00000w1nvKAAG\" #DAFFY_CUSTOMER_NAME=\"Acme Customer\" BASE_DOMAIN=\"<YOUR.BASEDOMAIN.COM>\" CLUSTER_NAME=\"<ENVIRONMENT_NAME>\" OCP_RELEASE=\"4.8.36\" VM_TSHIRT_SIZE=\"Large\" This file is where you store values that will define your environment and Daffy will use to build your environment. Place your file in : /data/daffy/env/ -env.sh ** Best practices is is your cluster name but not required. DAFFY_DEPLOYMENT_TYPE - Values POC/Demo/Enablement/HCCX/TechZone DAFFY_ISC_NUMBER - If Demo or POC, the ISC Record Number DAFFY_CUSTOMER_NAME - If Demo or POC, the Customer Name BASE_DOMAIN - Is your DNS name your cluster will use CLUSTER_NAM E - The name you want to give your OpenShift Cluster OCP_RELEASE - What version of OpenShift you want to Install VM_TSHIRT_SIZE - How large you want the OpenShift Cluster to be. Min and Large Supported today If MSP type install like ROKS, BASE_DOMAIN** is not needed. Optionally: As a starting point, you can copy a sample environment file from the samples folder located here: /data/daffy/env/samples/ -env.sh cd /data/daffy/env/samples Replace these values for the next command. = This is the sample file name for the platform you are planning to deploy your OCP Cluster. = This is the name of your environment file. As a best practice, we recommend you use the name of your cluster. This command will copy the the sample file and place it in the /data/daffy/env directory (back one folder) cp <platform>-env.sh ../<environment>-env.sh You are NOW ready to begin making the necessary edits to your /data/daffy/env/ -env.sh file for a deployment of OCP to a specific platform. Step 4: Install OpenShift on your selected platform \u00b6 IBM GYM KVM Google Cloud Platform Amazon Web Services Microsoft Azure VMWare VSphere IBM RedHat OpenShift","title":"Core Steps"},{"location":"Deploying-OCP/Core-steps/#step-1-access-your-bastion-server","text":"Create Bastion Steps *** If you do not have a bastion, above button/link will walk you thru the process to create a Linux bastion server.","title":"Step 1: Access your bastion Server"},{"location":"Deploying-OCP/Core-steps/#step-2-install-daffy","text":"Log into your Bastion Machine (as root) and run the following command to download the latest Daffy Scripts. wget http://get.daffy-installer.com/download-scripts/daffy-init.sh; chmod 777 daffy-init.sh;./daffy-init.sh","title":"Step 2: Install Daffy"},{"location":"Deploying-OCP/Core-steps/#step-3-create-envsh","text":"DAFFY_UNIQUE_ID=\"<YourID@ibm.com>\" #This is required - Values POC/Demo/Enablement/HCCX/TechZone DAFFY_DEPLOYMENT_TYPE=\"\" #If POC/Demo, these are required. #ISC number must be 18 characters #DAFFY_ISC_NUMBER=\"0045h00000w1nvKAAG\" #DAFFY_CUSTOMER_NAME=\"Acme Customer\" BASE_DOMAIN=\"<YOUR.BASEDOMAIN.COM>\" CLUSTER_NAME=\"<ENVIRONMENT_NAME>\" OCP_RELEASE=\"4.8.36\" VM_TSHIRT_SIZE=\"Large\" This file is where you store values that will define your environment and Daffy will use to build your environment. Place your file in : /data/daffy/env/ -env.sh ** Best practices is is your cluster name but not required. DAFFY_DEPLOYMENT_TYPE - Values POC/Demo/Enablement/HCCX/TechZone DAFFY_ISC_NUMBER - If Demo or POC, the ISC Record Number DAFFY_CUSTOMER_NAME - If Demo or POC, the Customer Name BASE_DOMAIN - Is your DNS name your cluster will use CLUSTER_NAM E - The name you want to give your OpenShift Cluster OCP_RELEASE - What version of OpenShift you want to Install VM_TSHIRT_SIZE - How large you want the OpenShift Cluster to be. Min and Large Supported today If MSP type install like ROKS, BASE_DOMAIN** is not needed. Optionally: As a starting point, you can copy a sample environment file from the samples folder located here: /data/daffy/env/samples/ -env.sh cd /data/daffy/env/samples Replace these values for the next command. = This is the sample file name for the platform you are planning to deploy your OCP Cluster. = This is the name of your environment file. As a best practice, we recommend you use the name of your cluster. This command will copy the the sample file and place it in the /data/daffy/env directory (back one folder) cp <platform>-env.sh ../<environment>-env.sh You are NOW ready to begin making the necessary edits to your /data/daffy/env/ -env.sh file for a deployment of OCP to a specific platform.","title":"Step 3: Create -env.sh"},{"location":"Deploying-OCP/Core-steps/#step-4-install-openshift-on-your-selected-platform","text":"IBM GYM KVM Google Cloud Platform Amazon Web Services Microsoft Azure VMWare VSphere IBM RedHat OpenShift","title":"Step 4: Install OpenShift on your selected platform"},{"location":"Deploying-OCP/GCP/","text":"GCP Install \u00b6 At this point, you have a bastion machine where you have installed the Daffy tool, created your core -env.sh and can execute the install of OCP on GCP . Platform Requirements \u00b6 To use Daffy on G oogle C loud P latform, there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For GCP, it breaks down to the following basic three items: Account Details - The account that you plan to install OpenShift Permissions - The permissions need to perform the install Quota - The ability to add new workload to that platform For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. [https://ibm.box.com/v/DaffyProviderRequirements](https://ibm.box.com/v/DaffyProviderRequirements Finding Provider Details \u00b6 To install Daffy on G oogle C loud P latform, the hardest part can be finding the provider details. Project ID: To find your GCP project you can refer to this: https://cloud.google.com/resource-manager/docs/creating-managing-projects You can list your Project ID from the Drop down You can see your Project ID from the Dashboard Identifying a region or zone \u00b6 Each region in Compute Engine contains a number of zones. Each zone name contains two parts that describe each zone in detail. The first part of the zone name is the region and the second part of the name describes the zone in the region: Region Regions are collections of zones. Zones have high-bandwidth, low-latency network connections to other zones in the same region. In order to deploy fault-tolerant applications that have high availability, Google recommends deploying applications across multiple zones and multiple regions. This helps protect against unexpected failures of components, up to and including a single zone or region. Choose regions that makes sense for your scenario. For example, if you only have customers in the US, or if you have specific needs that require your data to live in the US, it makes sense to store your resources in zones in the us-central1 region or zones in the us-east1 region. Region: To find a list of regions, you can refer to this: https://cloud.google.com/compute/docs/regions-zones What are service accounts? \u00b6 A service account is a special kind of account used by an application or compute workload, such as a Compute Engine virtual machine (VM) instance, rather than a person. Applications use service accounts to make authorized API calls , authorized as either the service account itself, or as Google Workspace or Cloud Identity users through domain-wide delegation . Service Account: For you to use Daffy to install on GCP , you need to create a service account that has the correct permission to install. https://cloud.google.com/iam/docs/creating-managing-service-account-keys#creating Permission: Within your GCP project, you would need to go to IAM Section and create/use Service Account. From the requirements doc , make sure your service account has the correct permissions. API Services Enabled: For each GCP project, you need to enable API access. Within your GCP project, you would need to enable each API needed for the OpenShift install. From the requirements doc , you can search for each API and confirm/enable each API Service. Quota: For each GCP project, you need to enable API access. Within your GCP project, you would need to enable each API needed for the OpenShift install. From the requirements doc , you can search for each API and confirm/enable each API Service. Search for \"Quotas\" within your GCP project Select the \"All Quotas\" Search for the quota you are looking for Verify Limit/Used Percentage Once you open the \"All Quotas\" Page, you can search for each quota to see its limits. \u00b6 Dedicated public host Zone: You will need to create a DZS hosted Zone project. For the OpenShift install, you need the following: Registered DNS Name - myexample.com GCP DNS Zone - myexample-com Transfer the domain to GCP Name services listed in your new GCP DNS Zone Setting up DNS for GCP Deployment with OpenShift: \u00b6 Environment File \u00b6 Deploying the OpenShift on GCP only requires three entries to your existing core environment file ( -env.sh) plus a local service account file. Note: You can look in the samples directory on your bastion for example of GCP install : /data/daffy/env/samples/ gcp-ipi-env.sh You can copy the sample file to build your new environment file. cp /data/daffy/env/samples/ gcp-ipi-env.sh /data/daffy/env/ -env.sh Valid Options: OCP_INSTALL_TYPE= gcp-ipi GCP_PROJECT_ID= GCP_REGION = Optional: OCP_CREATE_OPENSHIFT_CONTAINER_STORAGE =true If you plan to install a cloud pak and/or need storage, you need to set the flag to setup OCS Storage For GCP , you need to download your Service Key as well. Save this to your home path: ~/.gcp/osServiceAccount.json In your GCP project, go to IAM and Select Service accounts Select or Create new Service Account From the Service Account, select the Keys tab to create new Key. *** FYI after you create the Key, you can not view/download it. You can only get the details at the time of creation Execution \u00b6 To deploy your OCP cluster to GCP, run the build.sh script from the /data/daffy/ocp directory Once your cluster is fully deployed you can access the help menu which has a number of options. Note: is the first part of your name that you used for the -env.sh file Here is a full example for deploying OpenShift on GCP with the Daffy process.","title":"GCP"},{"location":"Deploying-OCP/GCP/#gcp-install","text":"At this point, you have a bastion machine where you have installed the Daffy tool, created your core -env.sh and can execute the install of OCP on GCP .","title":"GCP Install"},{"location":"Deploying-OCP/GCP/#platform-requirements","text":"To use Daffy on G oogle C loud P latform, there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For GCP, it breaks down to the following basic three items: Account Details - The account that you plan to install OpenShift Permissions - The permissions need to perform the install Quota - The ability to add new workload to that platform For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. [https://ibm.box.com/v/DaffyProviderRequirements](https://ibm.box.com/v/DaffyProviderRequirements","title":"Platform Requirements"},{"location":"Deploying-OCP/GCP/#finding-provider-details","text":"To install Daffy on G oogle C loud P latform, the hardest part can be finding the provider details. Project ID: To find your GCP project you can refer to this: https://cloud.google.com/resource-manager/docs/creating-managing-projects You can list your Project ID from the Drop down You can see your Project ID from the Dashboard","title":"Finding Provider Details"},{"location":"Deploying-OCP/GCP/#identifying-a-region-or-zone","text":"Each region in Compute Engine contains a number of zones. Each zone name contains two parts that describe each zone in detail. The first part of the zone name is the region and the second part of the name describes the zone in the region: Region Regions are collections of zones. Zones have high-bandwidth, low-latency network connections to other zones in the same region. In order to deploy fault-tolerant applications that have high availability, Google recommends deploying applications across multiple zones and multiple regions. This helps protect against unexpected failures of components, up to and including a single zone or region. Choose regions that makes sense for your scenario. For example, if you only have customers in the US, or if you have specific needs that require your data to live in the US, it makes sense to store your resources in zones in the us-central1 region or zones in the us-east1 region. Region: To find a list of regions, you can refer to this: https://cloud.google.com/compute/docs/regions-zones","title":"Identifying a region or zone"},{"location":"Deploying-OCP/GCP/#what-are-service-accounts","text":"A service account is a special kind of account used by an application or compute workload, such as a Compute Engine virtual machine (VM) instance, rather than a person. Applications use service accounts to make authorized API calls , authorized as either the service account itself, or as Google Workspace or Cloud Identity users through domain-wide delegation . Service Account: For you to use Daffy to install on GCP , you need to create a service account that has the correct permission to install. https://cloud.google.com/iam/docs/creating-managing-service-account-keys#creating Permission: Within your GCP project, you would need to go to IAM Section and create/use Service Account. From the requirements doc , make sure your service account has the correct permissions. API Services Enabled: For each GCP project, you need to enable API access. Within your GCP project, you would need to enable each API needed for the OpenShift install. From the requirements doc , you can search for each API and confirm/enable each API Service. Quota: For each GCP project, you need to enable API access. Within your GCP project, you would need to enable each API needed for the OpenShift install. From the requirements doc , you can search for each API and confirm/enable each API Service. Search for \"Quotas\" within your GCP project Select the \"All Quotas\" Search for the quota you are looking for Verify Limit/Used Percentage","title":"What are service accounts?"},{"location":"Deploying-OCP/GCP/#once-you-open-the-all-quotas-page-you-can-search-for-each-quota-to-see-its-limits","text":"Dedicated public host Zone: You will need to create a DZS hosted Zone project. For the OpenShift install, you need the following: Registered DNS Name - myexample.com GCP DNS Zone - myexample-com Transfer the domain to GCP Name services listed in your new GCP DNS Zone","title":"Once you open the \"All Quotas\" Page, you can search for each quota to see its limits."},{"location":"Deploying-OCP/GCP/#setting-up-dns-for-gcp-deployment-with-openshift","text":"","title":"Setting up DNS for GCP Deployment with OpenShift:"},{"location":"Deploying-OCP/GCP/#environment-file","text":"Deploying the OpenShift on GCP only requires three entries to your existing core environment file ( -env.sh) plus a local service account file. Note: You can look in the samples directory on your bastion for example of GCP install : /data/daffy/env/samples/ gcp-ipi-env.sh You can copy the sample file to build your new environment file. cp /data/daffy/env/samples/ gcp-ipi-env.sh /data/daffy/env/ -env.sh Valid Options: OCP_INSTALL_TYPE= gcp-ipi GCP_PROJECT_ID= GCP_REGION = Optional: OCP_CREATE_OPENSHIFT_CONTAINER_STORAGE =true If you plan to install a cloud pak and/or need storage, you need to set the flag to setup OCS Storage For GCP , you need to download your Service Key as well. Save this to your home path: ~/.gcp/osServiceAccount.json In your GCP project, go to IAM and Select Service accounts Select or Create new Service Account From the Service Account, select the Keys tab to create new Key. *** FYI after you create the Key, you can not view/download it. You can only get the details at the time of creation","title":"Environment File"},{"location":"Deploying-OCP/GCP/#execution","text":"To deploy your OCP cluster to GCP, run the build.sh script from the /data/daffy/ocp directory Once your cluster is fully deployed you can access the help menu which has a number of options. Note: is the first part of your name that you used for the -env.sh file Here is a full example for deploying OpenShift on GCP with the Daffy process.","title":"Execution"},{"location":"Deploying-OCP/IBM-gym/","text":"Overview \u00b6 The OpenShift Gym is a learning environment offering individuals the ability to deploy virtual machines to support installation of IBM technologies such as OpenShift and Cloud Paks. Prerequisites \u00b6 A Gym Membership request can be made by filling out the form. An active TECNet VPN ID is required to access and use the Gym. An email containing details on accessing the features of the OpenShift Gym is sent to the email address supplied once provisioning has completed. General information about the environment supplied is listed below. Refer to the provisioning email for detailed information. Set Up \u00b6 Make Sure you are connected to the Tecnet VPN, in initaial setup it may require you to reset your password. Launch Termius or your preferred Terminal Termius \u00b6 on the left tabe click on hosts click on + New Host Add the IP address that was given in the provisioning email Your preffered Terminal run command ssh admin@{Server IP address} -p 32222 Next you will copy the prepopulated env file in your home directory to your daffy env directory cp vmware-ipi-env.sh /data/daffy/env/{env-name}-env.sh You may make any changes needed in this file. Deploying \u00b6","title":"IBM Gym"},{"location":"Deploying-OCP/IBM-gym/#overview","text":"The OpenShift Gym is a learning environment offering individuals the ability to deploy virtual machines to support installation of IBM technologies such as OpenShift and Cloud Paks.","title":"Overview"},{"location":"Deploying-OCP/IBM-gym/#prerequisites","text":"A Gym Membership request can be made by filling out the form. An active TECNet VPN ID is required to access and use the Gym. An email containing details on accessing the features of the OpenShift Gym is sent to the email address supplied once provisioning has completed. General information about the environment supplied is listed below. Refer to the provisioning email for detailed information.","title":"Prerequisites"},{"location":"Deploying-OCP/IBM-gym/#set-up","text":"Make Sure you are connected to the Tecnet VPN, in initaial setup it may require you to reset your password. Launch Termius or your preferred Terminal","title":"Set Up"},{"location":"Deploying-OCP/IBM-gym/#termius","text":"on the left tabe click on hosts click on + New Host Add the IP address that was given in the provisioning email Your preffered Terminal run command ssh admin@{Server IP address} -p 32222 Next you will copy the prepopulated env file in your home directory to your daffy env directory cp vmware-ipi-env.sh /data/daffy/env/{env-name}-env.sh You may make any changes needed in this file.","title":"Termius"},{"location":"Deploying-OCP/IBM-gym/#deploying","text":"","title":"Deploying"},{"location":"Deploying-OCP/Pre-Req/","text":"Daffy Pre-Requirements \u00b6 Whats is required to use Daffy? \u00b6 Before you can use the Daffy scripts, you must have the following. You must have a SSH client on your local workstation. We highly recommend installing Termius as your SSH client. The Termius installer can be found here: Windows or Mac (Only the Free Version is needed) A Bastion Machine ( Create Bastion Instructions ) Ubuntu 20.04 (Minimum Requirements: 2 CPU, 2GB Memory) with full root access (VSphere-UPI, -IPI and -MSP) Ubuntu 20.04 (Minimum Requirements: 60+ CPU, 128GB+ Memory) with full root access (KVM-UPI) RHEL 8.X (Minimum Requirements: 2 CPU, 2GB Memory) with full root access ( -IPI and -MSP) Red Hat pull secret If you or your customer does not have a Red Hat pull secret - Sign up for 60 day trail for OpenShift: RedHat Pull secret Site - Important: If your installing on a customer owned platform account or a on-prem customer datacenter, you MUST instruct your customer to register for a trial account and use their pull secret for the install. Do not use your own pull secret for customer engagements. \u200b\u200b\u200b\u200b Sign up for IBM / Red Hat partner program NOTE: All IBMer's are entitled to the Red Hat partner program. Your Red Hat pull secret can ONLY be used for training and demo purposes. Do not provide your personal pull secret to customers. If you have a Red Hat account, you can find your existing pull secret here. - Login to Red Hat - Scroll down the page until you see \"Tokens\" and download the pull secret. Accessing Red Hat entitlements from your IBM Cloud Paks: - Accessing-red-hat-entitlements-from-your-cloud-paks IBM Entitlement Key 1. If you need to get your own IBM entitlement key you can get here . - Copy to clipboard and save to a local file 2. If you need create one for a customer you can submit request here. here . 3. Customer can use these links to request their own trail keys here. here .","title":"Pre Req"},{"location":"Deploying-OCP/Pre-Req/#daffy-pre-requirements","text":"","title":"Daffy Pre-Requirements"},{"location":"Deploying-OCP/Pre-Req/#whats-is-required-to-use-daffy","text":"Before you can use the Daffy scripts, you must have the following. You must have a SSH client on your local workstation. We highly recommend installing Termius as your SSH client. The Termius installer can be found here: Windows or Mac (Only the Free Version is needed) A Bastion Machine ( Create Bastion Instructions ) Ubuntu 20.04 (Minimum Requirements: 2 CPU, 2GB Memory) with full root access (VSphere-UPI, -IPI and -MSP) Ubuntu 20.04 (Minimum Requirements: 60+ CPU, 128GB+ Memory) with full root access (KVM-UPI) RHEL 8.X (Minimum Requirements: 2 CPU, 2GB Memory) with full root access ( -IPI and -MSP) Red Hat pull secret If you or your customer does not have a Red Hat pull secret - Sign up for 60 day trail for OpenShift: RedHat Pull secret Site - Important: If your installing on a customer owned platform account or a on-prem customer datacenter, you MUST instruct your customer to register for a trial account and use their pull secret for the install. Do not use your own pull secret for customer engagements. \u200b\u200b\u200b\u200b Sign up for IBM / Red Hat partner program NOTE: All IBMer's are entitled to the Red Hat partner program. Your Red Hat pull secret can ONLY be used for training and demo purposes. Do not provide your personal pull secret to customers. If you have a Red Hat account, you can find your existing pull secret here. - Login to Red Hat - Scroll down the page until you see \"Tokens\" and download the pull secret. Accessing Red Hat entitlements from your IBM Cloud Paks: - Accessing-red-hat-entitlements-from-your-cloud-paks IBM Entitlement Key 1. If you need to get your own IBM entitlement key you can get here . - Copy to clipboard and save to a local file 2. If you need create one for a customer you can submit request here. here . 3. Customer can use these links to request their own trail keys here. here .","title":"Whats is required to use Daffy?"},{"location":"Deploying-OCP/ROKS/","text":"At this point, you have a bastion machine where you have installed the Daffy tool, created your core environment-name -env.sh and can execute the install of OCP on ROKS. PREREQ CORE STEPS Step 1 Platform Requirements \u00b6 To use Daffy to provision R ed H at O penShift K ubernetes S ervices on IBM Cloud (ROKS) , there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For ROKS, it breaks down to the following basic two items: Account Details - The account that you plan to install ROKS Account Type - The account type needed to perform the install For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. https://ibm.box.com/v/DaffyProviderRequirements Step 2 Finding Provider Details \u00b6 To use Daffy to install ROKS, you must find the provider details. Luckily, Daffy automates this as it walks you through this process using ibmcloud CLI. Below are the steps you can use to make sure you use the right information. Account: To find more details IBM Cloud account and how to manage you can refer to this: https://cloud.ibm.com/docs/account?topic=account-account-getting-started You must have an IBMid before logging in and the link above can help create one. If you are an IBM employee, after the number will most likely be your name. You can list your Account ID from the Drop down Location/Zone: To find a list of available datacenter locations/zones, you can refer to this: https://cloud.ibm.com/docs/overview?topic=overview-locations#mzr-table Note: Daffy currently only supports single datacenter location installs with classic infrastructure Identifying a datacenter location/zone \u00b6 Regions are collections of zones. Zones have high-bandwidth, low-latency network connections to other zones in the same region. In order to deploy fault-tolerant applications that have high availability, IBM recommends deploying applications across multiple zones and multiple regions. This helps protect against unexpected failures of components, up to and including a single zone or region. Choose regions that makes sense for your scenario. For example, if you only have customers in the US, or if you have specific needs that require your data to live in the US, it makes sense to store your resources in zones in the dal13 zone or in the wdc07 zone. Daffy currently defaults to dal13 when deploying a ROKS cluster Account Type: For you to use Daffy to install on ROKS, you need to have a Pay-As-You-Go or subscription IBM Cloud account. https://cloud.ibm.com/docs/account?topic=account-accounts What are account types? \u00b6 Your IBM Cloud account includes many interacting components and systems for resource, user, and access management. Concepts like how certain components are connected or how access works help you in understanding how to set up your account type. Many features are free to use regardless of account type. Step 3 Environment File \u00b6 Deploying OpenShift on ROKS only requires one entry to your existing core environment file ( -env.sh). Note: You can look in the samples directory on your bastion for example of ROKS install : /data/daffy/env/samples/roks-msp-env.sh You can copy the sample file to build your new environment file. cp /data/daffy/env/samples/roks-msp-env.sh /data/daffy/env/<ENVIRONMENT_NAME>-env.sh Valid Options: OCP_INSTALL_TYPE= roks-msp Optional: ROKS_ZONE=dal13 OCP_INSTALL_TYPE=\"roks-msp\" #ROKS_ZONE=\"dal13\" Step 4 Execution \u00b6 To deploy your OCP cluster to ROKS, run the build.sh script from the /data/daffy/ocp directory. The installer will ask you a number of questions to login to ibmcloud via the CLI. When prompted with a region, select any but stay within your geography. For instance, us-south. This is used to talk with IBM Cloud via the right API endpoint. /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> Once your cluster is fully deployed you can access the help menu which has a number of options. Note: is the first part of your name that you used for the -env.sh file /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> --help Here is a full example for deploying OpenShift on ROKS with the Daffy process.","title":"ROKS"},{"location":"Deploying-OCP/ROKS/#step-1-platform-requirements","text":"To use Daffy to provision R ed H at O penShift K ubernetes S ervices on IBM Cloud (ROKS) , there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For ROKS, it breaks down to the following basic two items: Account Details - The account that you plan to install ROKS Account Type - The account type needed to perform the install For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. https://ibm.box.com/v/DaffyProviderRequirements","title":"Step 1 Platform Requirements"},{"location":"Deploying-OCP/ROKS/#step-2-finding-provider-details","text":"To use Daffy to install ROKS, you must find the provider details. Luckily, Daffy automates this as it walks you through this process using ibmcloud CLI. Below are the steps you can use to make sure you use the right information. Account: To find more details IBM Cloud account and how to manage you can refer to this: https://cloud.ibm.com/docs/account?topic=account-account-getting-started You must have an IBMid before logging in and the link above can help create one. If you are an IBM employee, after the number will most likely be your name. You can list your Account ID from the Drop down Location/Zone: To find a list of available datacenter locations/zones, you can refer to this: https://cloud.ibm.com/docs/overview?topic=overview-locations#mzr-table Note: Daffy currently only supports single datacenter location installs with classic infrastructure","title":"Step 2 Finding Provider Details"},{"location":"Deploying-OCP/ROKS/#identifying-a-datacenter-locationzone","text":"Regions are collections of zones. Zones have high-bandwidth, low-latency network connections to other zones in the same region. In order to deploy fault-tolerant applications that have high availability, IBM recommends deploying applications across multiple zones and multiple regions. This helps protect against unexpected failures of components, up to and including a single zone or region. Choose regions that makes sense for your scenario. For example, if you only have customers in the US, or if you have specific needs that require your data to live in the US, it makes sense to store your resources in zones in the dal13 zone or in the wdc07 zone. Daffy currently defaults to dal13 when deploying a ROKS cluster Account Type: For you to use Daffy to install on ROKS, you need to have a Pay-As-You-Go or subscription IBM Cloud account. https://cloud.ibm.com/docs/account?topic=account-accounts","title":"Identifying a datacenter location/zone"},{"location":"Deploying-OCP/ROKS/#what-are-account-types","text":"Your IBM Cloud account includes many interacting components and systems for resource, user, and access management. Concepts like how certain components are connected or how access works help you in understanding how to set up your account type. Many features are free to use regardless of account type.","title":"What are account types?"},{"location":"Deploying-OCP/ROKS/#step-3-environment-file","text":"Deploying OpenShift on ROKS only requires one entry to your existing core environment file ( -env.sh). Note: You can look in the samples directory on your bastion for example of ROKS install : /data/daffy/env/samples/roks-msp-env.sh You can copy the sample file to build your new environment file. cp /data/daffy/env/samples/roks-msp-env.sh /data/daffy/env/<ENVIRONMENT_NAME>-env.sh Valid Options: OCP_INSTALL_TYPE= roks-msp Optional: ROKS_ZONE=dal13 OCP_INSTALL_TYPE=\"roks-msp\" #ROKS_ZONE=\"dal13\"","title":"Step 3 Environment File"},{"location":"Deploying-OCP/ROKS/#step-4-execution","text":"To deploy your OCP cluster to ROKS, run the build.sh script from the /data/daffy/ocp directory. The installer will ask you a number of questions to login to ibmcloud via the CLI. When prompted with a region, select any but stay within your geography. For instance, us-south. This is used to talk with IBM Cloud via the right API endpoint. /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> Once your cluster is fully deployed you can access the help menu which has a number of options. Note: is the first part of your name that you used for the -env.sh file /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> --help Here is a full example for deploying OpenShift on ROKS with the Daffy process.","title":"Step 4 Execution"},{"location":"Deploying-OCP/TechZone/","text":"","title":"TechZone"},{"location":"Deploying-OCP/VSphere/","text":"","title":"VSphere"},{"location":"Deploying-OCP/kvm/","text":"At this point, you have a bastion machine where you have installed the Daffy tool, created your core environment-name -env.sh and can execute the install of OCP on ROKS. Step 1 Platform Requirements \u00b6 To use Daffy on K ernel-based V irtual M achine, there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For KVM , it breaks down to the following three basic items: Hardware - Enough to run the OCP Cluster based on T-Shirt Sizing OS Version - Ubuntu 20.0.4 Permission - Full root authority For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. https://ibm.box.com/v/DaffyProviderRequirements Public DNS Setup: You will need to create a DNS entries and domain. For the OpenShift install, you need the following: Registered DNS Name - myexample.com DNS Entries- myexample-com api. . myexample.com ---> api-int. . myexample.com ---> *.apps. .myexample.com ---> Setting up DNS for KVM Deployment with OpenShift: INSERT VIDEO Here Step 2 Environment File \u00b6 Deploying the OpenShift on K ernel-based V irtual M achine only requires three entries to your existing core environment file ( -env.sh) plus a local service account file. Note: You can look in the samples directory on your bastion for example of K ernel-based V irtual M achine install : /data/daffy/env/samples/kvm-upi-env.sh You can copy the sample file to build your new environment file. cp /data/daffy/env/samples/kvm-upi-env.sh /data/daffy/env/ -env.sh Valid Options: OCP_INSTALL_TYPE= kvm-upi Optional: BASTION_HOST =\"xxx.xxx.xxx.xxx\" If your host does not have its own public IP address, you need to specify the bastion IP address that the OCP cluster would use to reach your Bastion host, its local IP address you used to connect to the bastion: OCP_CREATE_OPENSHIFT_CONTAINER_STORAGE= true If you plan to install a cloud pak and/or need storage, you need to set the flag to setup OCS Storage Step 3 Execution \u00b6 To deploy your OCP cluster to Kernel-based Virtual Machine, run the build.sh script from the /data/daffy/ocp directory /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> Once your cluster is fully deployed you can access the help menu which has a number of options. Note: is the first part of your name that you used for the -env.sh file /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> --help Here is a full example for deploying OpenShift on Kernel-based Virtual Machine with the Daffy process.","title":"kvm"},{"location":"Deploying-OCP/kvm/#step-1-platform-requirements","text":"To use Daffy on K ernel-based V irtual M achine, there are some platform info and requirements that need to be gathered or met. We have a simple doc that you should refer to that list all providers and what would be needed. For KVM , it breaks down to the following three basic items: Hardware - Enough to run the OCP Cluster based on T-Shirt Sizing OS Version - Ubuntu 20.0.4 Permission - Full root authority For detailed list of the above, you can find in the Daffy Provider Requirements. Please review before proceeding. https://ibm.box.com/v/DaffyProviderRequirements Public DNS Setup: You will need to create a DNS entries and domain. For the OpenShift install, you need the following: Registered DNS Name - myexample.com DNS Entries- myexample-com api. . myexample.com ---> api-int. . myexample.com ---> *.apps. .myexample.com ---> Setting up DNS for KVM Deployment with OpenShift: INSERT VIDEO Here","title":"Step 1 Platform Requirements"},{"location":"Deploying-OCP/kvm/#step-2-environment-file","text":"Deploying the OpenShift on K ernel-based V irtual M achine only requires three entries to your existing core environment file ( -env.sh) plus a local service account file. Note: You can look in the samples directory on your bastion for example of K ernel-based V irtual M achine install : /data/daffy/env/samples/kvm-upi-env.sh You can copy the sample file to build your new environment file. cp /data/daffy/env/samples/kvm-upi-env.sh /data/daffy/env/ -env.sh Valid Options: OCP_INSTALL_TYPE= kvm-upi Optional: BASTION_HOST =\"xxx.xxx.xxx.xxx\" If your host does not have its own public IP address, you need to specify the bastion IP address that the OCP cluster would use to reach your Bastion host, its local IP address you used to connect to the bastion: OCP_CREATE_OPENSHIFT_CONTAINER_STORAGE= true If you plan to install a cloud pak and/or need storage, you need to set the flag to setup OCS Storage","title":"Step 2 Environment File"},{"location":"Deploying-OCP/kvm/#step-3-execution","text":"To deploy your OCP cluster to Kernel-based Virtual Machine, run the build.sh script from the /data/daffy/ocp directory /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> Once your cluster is fully deployed you can access the help menu which has a number of options. Note: is the first part of your name that you used for the -env.sh file /data/daffy/ocp/build.sh <ENVIRONMENT_NAME> --help Here is a full example for deploying OpenShift on Kernel-based Virtual Machine with the Daffy process.","title":"Step 3 Execution"},{"location":"Meet-the-Team/Meat-the-Team/","text":"","title":"Meat the Team"},{"location":"Meet-the-Team/Workstreams/","text":"","title":"Workstreams"},{"location":"More/Glossary/","text":"","title":"Glossary"},{"location":"More/FAQ/Deployment-Estimates/","text":"","title":"Deployment Estimates"},{"location":"More/FAQ/FAQ/","text":"","title":"FAQ"},{"location":"More/FAQ/IBM-Entitlement%20Keys/","text":"","title":"IBM Entitlement Keys"},{"location":"Overview/Tools-Installed/","text":"","title":"Tools Installed"},{"location":"Request-Forms/Demo-Request/","text":"","title":"Demo Request"},{"location":"Request-Forms/Feature-Requests/","text":"","title":"Feature Request"},{"location":"Request-Forms/Get-Involved/","text":"","title":"Get Involved"},{"location":"Request-Forms/L200-Adv-Training/","text":"","title":"L200 Adv Training"},{"location":"Request-Forms/POC-Request-Form/","text":"","title":"POC Request Form"},{"location":"Request-Forms/Training/","text":"","title":"Training"},{"location":"Supporting-Software/Create-Your-Own-Bastion/","text":"What is a bastion server? Why does it exist? \u00b6 A bastion host is a server whose purpose is to provide access to a private network from an external network, such as the Internet. Because of its exposure to potential attack, a bastion host must minimize the chances of penetration. Openshift uses a bastion to help create a running cluster. A bastion can be reused for multiple clusters. In some scenarios for POC purposes such as User Provisioned Infrastructure (UPI), the bastion can be used as the proxy to the cluster. Bastion servers can be installed anywhere. This guide assumes the bastion server is Ubuntu 20.04 Minimal and will be in the IBM Cloud. Requirements for completing this task is to have an IBMid, an IBM cloud account, and a local SSH key. For more information, go to Daffy Prerequisites. Detailed below are the instructions to build your own bastion to do an IPI or MSP install. Bastion Server Using IBM Cloud \u00b6 First, open a web browser and go to http://cloud.ibm.com Enter your id and click 'Continue' Once logged in, select 'Catalog' in the top menu bar Once the Catalog is loaded, select 'Compute' or search the catalog for Virtual Servers. Select 'Virtual Server for Classic' Alternative: Skip step 3 and search for \"virtual server\", choosing \"virtual server for classic\". Both options achieve the same thing. Fill out the details. (Public, hostname can be anything, and so can domain \u2013 feel free to leave what is there originally for your domain). Choose your billing method based on needs to be either Hourly or Monthly (~$40/mo.) and choose a Location. Scroll down and fill out the remainder of the information. Choose a server type and select your SSH key so you can login. Finally, make sure you have the Ubuntu 20.04 Operating System selected. Note: You can use any other available tool to create a key if needed Click the agreement on the right-hand pane and select 'Create' This will take you to a device page. You can search for your bastion you have created. Once your server is done provisioning and has a start date, you can login to it via Termius using the Public IP address. **If connecting to a VPN to connect to the network, you will use the Private IP address, but Public will be used more frequently. Create a new host in Termius: use your SSH key as the password , use root as the username , input the Public IP Address from the device list as your host's address, and create a label. **If you don't use a SSH Key, you can go into the details of the bastion you created by double clicking on it and going to the passwords section. This password will not show until provisioning is complete. Once you have connected your bastion to Termius , install Daffy to the terminal of your newly created host. IBM Technology Zone \u00b6 An alternative to creating a bastion using a paid IBM Cloud account is to use IBM Technology Zone. Use this link to navigate to IBM Technology Zone: https://techzone.ibm.com/collection/base-images Scroll down to environments, and choose IBM Virtual Server Instance (Classic) From there, complete your reservation. Make sure to fill out items 1 \u2013 4 , leaving the other fields blank .","title":"Create Your Own Bastion"},{"location":"Supporting-Software/Create-Your-Own-Bastion/#what-is-a-bastion-server-why-does-it-exist","text":"A bastion host is a server whose purpose is to provide access to a private network from an external network, such as the Internet. Because of its exposure to potential attack, a bastion host must minimize the chances of penetration. Openshift uses a bastion to help create a running cluster. A bastion can be reused for multiple clusters. In some scenarios for POC purposes such as User Provisioned Infrastructure (UPI), the bastion can be used as the proxy to the cluster. Bastion servers can be installed anywhere. This guide assumes the bastion server is Ubuntu 20.04 Minimal and will be in the IBM Cloud. Requirements for completing this task is to have an IBMid, an IBM cloud account, and a local SSH key. For more information, go to Daffy Prerequisites. Detailed below are the instructions to build your own bastion to do an IPI or MSP install.","title":"What is a bastion server? Why does it exist?"},{"location":"Supporting-Software/Create-Your-Own-Bastion/#bastion-server-using-ibm-cloud","text":"First, open a web browser and go to http://cloud.ibm.com Enter your id and click 'Continue' Once logged in, select 'Catalog' in the top menu bar Once the Catalog is loaded, select 'Compute' or search the catalog for Virtual Servers. Select 'Virtual Server for Classic' Alternative: Skip step 3 and search for \"virtual server\", choosing \"virtual server for classic\". Both options achieve the same thing. Fill out the details. (Public, hostname can be anything, and so can domain \u2013 feel free to leave what is there originally for your domain). Choose your billing method based on needs to be either Hourly or Monthly (~$40/mo.) and choose a Location. Scroll down and fill out the remainder of the information. Choose a server type and select your SSH key so you can login. Finally, make sure you have the Ubuntu 20.04 Operating System selected. Note: You can use any other available tool to create a key if needed Click the agreement on the right-hand pane and select 'Create' This will take you to a device page. You can search for your bastion you have created. Once your server is done provisioning and has a start date, you can login to it via Termius using the Public IP address. **If connecting to a VPN to connect to the network, you will use the Private IP address, but Public will be used more frequently. Create a new host in Termius: use your SSH key as the password , use root as the username , input the Public IP Address from the device list as your host's address, and create a label. **If you don't use a SSH Key, you can go into the details of the bastion you created by double clicking on it and going to the passwords section. This password will not show until provisioning is complete. Once you have connected your bastion to Termius , install Daffy to the terminal of your newly created host.","title":"Bastion Server Using IBM Cloud"},{"location":"Supporting-Software/Create-Your-Own-Bastion/#ibm-technology-zone","text":"An alternative to creating a bastion using a paid IBM Cloud account is to use IBM Technology Zone. Use this link to navigate to IBM Technology Zone: https://techzone.ibm.com/collection/base-images Scroll down to environments, and choose IBM Virtual Server Instance (Classic) From there, complete your reservation. Make sure to fill out items 1 \u2013 4 , leaving the other fields blank .","title":"IBM Technology Zone"},{"location":"Supporting-Software/DB2/","text":"","title":"DB2"},{"location":"Supporting-Software/IBM-LDAP/","text":"","title":"IBM LDAP"},{"location":"Supporting-Software/Turbo/","text":"Turbonomic \u00b6","title":"Turbo"},{"location":"Supporting-Software/Turbo/#turbonomic","text":"","title":"Turbonomic"},{"location":"Tips-%26-Tricks/Common-Issues/","text":"","title":"Common Issues"},{"location":"Tips-%26-Tricks/Edit-Files/","text":"","title":"Edit Files"},{"location":"Tips-%26-Tricks/Environment-File/","text":"","title":"Environment File"}]}